y <- xy[,2]
xknots <- quantile(x, prob=(0:nknots)/(1+nknots))         # Knot locations
X <- cbind(1,x,x^2)                                       # Polynomial bases
for(xknot in xknots) { X <- cbind(X, pmax(x-xknot,0)^3) } # Spline bases
X.svd <- svd(X)                                  # SVD for orthogonalization
X.svd$d <- pmax(X.svd$d, max(X.svd$d)/1E12)      # Numeric stability: condition number 1E12
b <-  X.svd$v %*% ((t(X.svd$u) %*% y) / X.svd$d) # Coefficients
X.out <- cbind(1,x.out,x.out^2)
for(xknot in xknots) { X.out <- cbind(X.out, pmax(x.out-xknot,0)^3) }
y.out <- X.out %*% b
xy.out <- cbind(x=x.out, y=y.out)
xy.out
}
xy <- cbind(Students$WEIGHT,Students$HEIGHT)      # Select from 'Students' the two columns 'WEIGHT' and 'HEIGHT' in this order!
xy.out <- reg.spline(xy)  # Apply reg.spline() to 'xy'.
plot(xy[,1], xy[,2],pch=16) # Plot the data with filled circles.
lines(xy.out[,1], xy.out[,2],col='blue',lwd=4)   # Draw the fitted curve as a thick blue line.
N <- length(Students$HEIGHT)  # Store the sample size (that's NOT the number of bootstrap datasets!).
for(i in 1: 500) {   # The for-loop that draws 500 curves fitted to bootstrap datasets; you can hardcode 500.
sel <- sample(N,replace=T)           # Integer vector that selects the rows for the bootstrap dataset (length=N)
xy.boot <- xy[sel,] # Bootstrap dataset (Nx2)
xy.boot.out <- reg.spline(xy.boot, x.out = xy.out[,1])   # Apply reg.spline(); set 'x.out=' appropriately -- don't use the default!
lines(xy.boot.out[,1], xy.boot.out[,2],col='green')  # Draw the bootstrap curve in green on top of what's there (default line width).
}
points(xy[,1], xy[,2],pch=16)      # Redraw the data points ('xy') with filled circles.
lines(xy.out[,1], xy.out[,2],col='blue',lwd=4)  # Redraw the original curve ('xy.out'), blue and thick.
## Excercise 5.3
cards = 1..52
cards = 1:52
cards
sample(5)
sample(52,5)
sample(52,5)
sample(52,5)
sample(52,5)
sample(52,5)
sample(cards,5)
sample(cards,5)
sample(cards,5)
sample(cards,5)
sample(cards,5)
sample(cards,5)
sample(cards,5)
which(sample(cards,5))
which(true)
cardSample = sample(cards,5)
cardSample == 1
cardSample == c(1,2,3,4)
s = c(1,2,3,4)
s ==1
which(s==1)
cardSample
cardSample %in% c(1,2,3,4)
length(which(cardSample %in% c(1,2,3,4)))
cardSample = sample(cards,5)
length(which(cardSample %in% c(1,2,3,4)))
cardSample = sample(cards,5)
length(which(cardSample %in% c(1,2,3,4)))
cardSample = sample(cards,5)
length(which(cardSample %in% c(1,2,3,4)))
cardSample = sample(cards,5)
length(which(cardSample %in% c(1,2,3,4)))
cardSample = sample(cards,5)
length(which(cardSample %in% c(1,2,3,4)))
cardSample = sample(cards,5)
length(which(cardSample %in% c(1,2,3,4)))
cardSample
radius <- 1:20
radius <- 1:20
area <- pi*radiuŝ2
plot(radius,area, main= 'Area as function of radius')
area <- pi*radiuŝ2
area <- pi*radius^2
plot(radius,area, main= 'Area as function of radius')
radius <- 1:100
volume <- 4/3 * pi*radius^3
radius <- 1:100
volume <- 4/3 * pi*radius^3
plot(radius,volume, main= 'Volume as function of radius')
n <- 1000 # Number of coin flips
coinflips <- sample(0:1,n,replace=TRUE)
heads <- cumsum(coinflips)
prop <- heads/(1:n)
plot(1:n,prop,type="l",xlab='Number of coins',
ylab='Running average',
main='Running proportion of heads in 1000
coin flips')
abline(h=0.5)
prop
heads
coinflips
heads
n <- 1000 # Number of coin flips
coinflips <- sample(0:1,n,replace=TRUE,prob = c(0.49,0.51))
heads <- cumsum(coinflips)
prop <- heads/(1:n)
plot(1:n,prop,type="l",xlab='Number of coins',
ylab='Running average',
main='Running proportion of heads in 1000
coin flips')
abline(h=0.5)
author: "Aditya Srivatsan"
author: "Aditya Srivatsan"
date: "January 16, 2018"
date: "January 16, 2018"
cars
cars
cars
x = 3
n <- 1000 # Number of coin flips
coinflips <- sample(0:1,n,replace=TRUE,prob = c(0.49,0.51)) # only line of code changed!
heads <- cumsum(coinflips)
prop <- heads/(1:n)
plot(1:n,prop,type="l",xlab='Number of coins',
ylab='Running average',
main='Running proportion of heads in 1000
coin flips')
abline(h=0.5)
numeric(1000)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE) ==1
length(sample(0:1,3,replace=TRUE) ==1)
length(which(sample(0:1,3,replace=TRUE) ==1))
length(which(sample(0:1,3,replace=TRUE) ==1))
length(which(sample(0:1,3,replace=TRUE) ==1))
length(which(sample(0:1,3,replace=TRUE) ==1))
length(which(sample(0:1,3,replace=TRUE) ==1))
sample(0:1,3,replace=TRUE)
x = sample(0:1,3,replace=TRUE)
x
length(which(x==1))
expectedValueHead <- replicate(trials,
length(which(sample(0:1,3,replace=TRUE) ==1 )))
trials <- 100000
expectedValueHead <- replicate(trials,
length(which(sample(0:1,3,replace=TRUE) ==1 )))
expectedValueHead
mean(expectedValueHead)
var(expectedValueHead)
3 ==3
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
sample(0:1,3,replace=TRUE)
x =sample(0:1,3,replace=TRUE)
x
x =sample(0:1,3,replace=TRUE)
x
which(x)
which(x==1)
x
x == 1
length(which(x ==1))
length(which(x ==1)) ==1
which(length(which(x ==1)) ==1)
trials <- 100000
oneHead <- replicate(trails,
which(length(which(sample(0:1,3,replace=TRUE) ==1) ==1)))
trials <- 100000
oneHead <- replicate(trails,
which(length(which(sample(0:1,3,replace=TRUE) ==1) ==1)))
which(length(which(x ==1)) ==1)
oneHead <- replicate(trails,
which(length(which(sample(0:1,3,replace=TRUE) ==1) ==1)))
trials <- 100000
oneHead <- replicate(trials,
which(length(which(sample(0:1,3,replace=TRUE) ==1) ==1)))
oneHead <- replicate(trials,
which(length(which(sample(0:1,3,replace=TRUE) ==1))) == 1)
length(which(sample(0:1,3,replace=TRUE) ==1))) == 1
length(which(sample(0:1,3,replace=TRUE) ==1))) == 1)
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
oneHead <- replicate(trials,
which(length(which(sample(0:1,3,replace=TRUE) ==1)) == 1))
oneHead
mean(oneHead)
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1)
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
length(which(sample(0:1,3,replace=TRUE) ==1)) == 1
expectedValueHead <- replicate(trials,
length(which(sample(0:1,3,replace=TRUE) ==1 )))
t = 1:10
beta = 1
alpha = 1
plot(beta + t -1 / alpha + beta + t-1)
t = 1:10
beta = 1
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1),ylim = c(-10,10))
t = -10:10
beta = 1
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1),ylim = c(-10,10))
t = -10:10
beta = 1
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1),ylim = c(-10,10))
t = 1:20
beta = 1
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1),ylim = c(-10,10))
t = 1:20
beta = 10
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1),ylim = c(-10,10))
t = 1:20
beta = 10
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1),ylim = c(-10,10))
t = 1:20
beta = 10
alpha = 30
plot((beta + t -1) / (alpha + beta + t-1),ylim = c(-10,10))
t = 1:20
beta = 10
alpha = 30
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 10
alpha = 20
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 50
alpha = 20
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 50
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 50
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 10
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1.5
alpha = 0.5
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 0.5
alpha = 1.5
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 0.5
alpha = 1.5
plot((beta + t -1) / (alpha + beta + t-1))
beta = 1.5
alpha = 0.5
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 5
alpha = 5
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 0.5
alpha = 0.5
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 50
alpha = 50
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 50
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 50
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 100
alpha = 100
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 10
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 10
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
beta = 10
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 10
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 1
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 10
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
alpha = 10
plot((beta + t -1) / (alpha + beta + t-1))
t = 1:20
beta = 10
alpha = 1
plot((beta + t -1) / (alpha + beta + t-1))
load("~/Documents/Penn/SeniorFall/Practicum Project/Semester1Workspace.RData")
colnames(totalDf)
head(totalDf$tract)
table(totalDf$tract)
table(totalDf$Y)
colnames(totalDf)
table(totalDf$X.y)
head(totalDf$X.y)
head(totalDf$Y)
colnames(totalDf)
excelDfStat = totalDf[,c('Year','Month','tract','Y')]
head(excelDfStat)
dim(excelDfStat)
library(xlsx)
install.package('xlsx')
write.xlsx
library(xlsx)
write.csv(x = excelDfStat,file = 'PhillyCrimeNBDModel.csv')
dir()
getwd()
colnames(totalDf)
setwd(dir='Documents/Penn/SeniorFall/Practicum Project/Philadelphia-Crime-Analysis-Practicum')
library(logOfGamma)
library(MASS)
library(rpart)
library(dplyr)
library(olsrr)
library(glmnet)
library(dplyr)
crimeDf = read.csv(file = 'ProcessedDataSets/TotalInfoDF_03_12_2019.csv')
weatherDf = read.csv(file='ProcessedDataSets/weatherPhiladelphiaData20062015.csv')
totalDf = merge(crimeDf,weatherDf,by.x = c('Year','Month'), by.y = c('Year','Month'))
## Filtering columns
nonNumericCols = c('YearTract','violent','nonviolent','Total_y','vice','X.y','X.x','count_inf',
'hispanic','culture_recreation')
totalFilteredDf = totalDf[,!(names(totalDf) %in% nonNumericCols)]
tractNum = length(unique(totalDf$tract))
XtrainTract = totalFilteredDf[totalDf$Year %in% 2006:2013,]
XtestTract = totalFilteredDf[totalDf$Year %in% 2014:2015,]
Xtrain = XtrainTract[,!(names(XtrainTract) %in% c('tract'))]
Xtest = XtestTract[,!(names(XtestTract) %in% c('tract'))]
evaluateError = function(model, trainData, testData) {
inSampErr = mean((trainData$Y - predict(model))^2)
outSampErr = mean((testData$Y - predict(model,newdata = testData))^2)
c(inSampErr,outSampErr)
}
evaluateErrPois = function(model,trainData,testData) {
inSampErr = mean((trainData$Y - exp(predict(model)))^2)
outSampErr = mean((testData$Y - exp(predict(model,newdata = testData)))^2)
c(inSampErr,outSampErr)
}
visualizeModelYear = function(model,trainData,year) {
Xvisual = trainData
Xvisual['pred'] = predict(model)
XYear = Xvisual[Xvisual$Year == year,]
XYearAgg = XYear %>% group_by(tract) %>% summarise_all(funs(sum))
hist(XYearAgg$pred,col='blue')
hist(XYearAgg$Y,col='red',add=T)
}
### Looking at tract
visualizeModelTract = function(model,trainData,tract) {
Xvisual = trainData
Xvisual['pred'] = predict(model)
Xtract = Xvisual[Xvisual$tract == tract,]
plot(Xtract$Y,col='red',type = 'line')
lines(Xtract$pred,col='blue',type='line')
}
genMatirx = as.matrix(Xtrain %>% select(-one_of(c('Y'))))
crossval <-  cv.glmnet(x = genMatirx, y = Xtrain[,'Y'])
lassoTotalModel = glmnet(genMatirx,alpha = 1, Xtrain[,'Y'], lambda = lamMin)
lamMin = crossval$lambda.min
lassoTotalModel = glmnet(genMatirx,alpha = 1, Xtrain[,'Y'], lambda = lamMin)
coeffLasso = coefficients(lassoTotalModel)[,1]
coeffLasso = coeffLasso[coeffLasso !=0]
coeffLasso = coeffLasso[-9]
lassoFilterColumns = names(coeffLasso)
coeffLasso
coeffLasso = coeffLasso[-9]
lassoFilterColumns = names(coeffLasso)
coeffLasso
lassoTotalModel = glmnet(genMatirx,alpha = 1, Xtrain[,'Y'], lambda = lamMin)
coeffLasso = coefficients(lassoTotalModel)[,1]
coeffLasso = coeffLasso[coeffLasso !=0]
coeffLasso = coeffLasso[-9]
lassoFilterColumns = names(coeffLasso)
coeffLasso
crimeDf = read.csv(file = 'ProcessedDataSets/TotalInfoDF_03_12_2019.csv')
weatherDf = read.csv(file='ProcessedDataSets/weatherPhiladelphiaData20062015.csv')
totalDf = merge(crimeDf,weatherDf,by.x = c('Year','Month'), by.y = c('Year','Month'))
## Filtering columns
nonNumericCols = c('YearTract','violent','nonviolent','Total_y','vice','X.y','X.x','count_inf',
'hispanic','culture_recreation')
totalFilteredDf = totalDf[,!(names(totalDf) %in% nonNumericCols)]
tractNum = length(unique(totalDf$tract))
XtrainTract = totalFilteredDf[totalDf$Year %in% 2006:2013,]
XtestTract = totalFilteredDf[totalDf$Year %in% 2014:2015,]
Xtrain = XtrainTract[,!(names(XtrainTract) %in% c('tract'))]
Xtest = XtestTract[,!(names(XtestTract) %in% c('tract'))]
evaluateError = function(model, trainData, testData) {
inSampErr = mean((trainData$Y - predict(model))^2)
outSampErr = mean((testData$Y - predict(model,newdata = testData))^2)
c(inSampErr,outSampErr)
}
evaluateErrPois = function(model,trainData,testData) {
inSampErr = mean((trainData$Y - exp(predict(model)))^2)
outSampErr = mean((testData$Y - exp(predict(model,newdata = testData)))^2)
c(inSampErr,outSampErr)
}
visualizeModelYear = function(model,trainData,year) {
Xvisual = trainData
Xvisual['pred'] = predict(model)
XYear = Xvisual[Xvisual$Year == year,]
XYearAgg = XYear %>% group_by(tract) %>% summarise_all(funs(sum))
hist(XYearAgg$pred,col='blue')
hist(XYearAgg$Y,col='red',add=T)
}
### Looking at tract
visualizeModelTract = function(model,trainData,tract) {
Xvisual = trainData
Xvisual['pred'] = predict(model)
Xtract = Xvisual[Xvisual$tract == tract,]
plot(Xtract$Y,col='red',type = 'line')
lines(Xtract$pred,col='blue',type='line')
}
genMatirx = as.matrix(Xtrain %>% select(-one_of(c('Y'))))
crossval <-  cv.glmnet(x = genMatirx, y = Xtrain[,'Y'])
lamMin = crossval$lambda.min
lassoTotalModel = glmnet(genMatirx,alpha = 1, Xtrain[,'Y'], lambda = lamMin)
summary(lassoTotalModel)
coeffLasso = coefficients(lassoTotalModel)[,1]
coeffLasso = coeffLasso[coeffLasso !=0]
coeffLasso = coeffLasso[-9]
lassoFilterColumns = names(coeffLasso)
coeffLasso
filteredDTModelAT = rpart(Y ~ .,data=XLassFilterTrain,method='anova')
## Normal Linear Regression.
XLassFilterTrain = Xtrain[,names(Xtrain) %in% c(names(coeffLasso),'Y')]
XLassFilterTest = Xtest[,names(Xtest) %in% c(names(coeffLasso),'Y')]
linModLassFilter = lm(Y ~ ., data = XLassFilterTrain)
summary(linModLassFilter)
genMatirx = as.matrix(Xtrain %>% select(-one_of(c('Y'))))
lamMin = crossval$lambda.min
lamMin
crimeDf = read.csv(file = 'ProcessedDataSets/TotalInfoDF_03_12_2019.csv')
weatherDf = read.csv(file='ProcessedDataSets/weatherPhiladelphiaData20062015.csv')
totalDf = merge(crimeDf,weatherDf,by.x = c('Year','Month'), by.y = c('Year','Month'))
## Filtering columns
nonNumericCols = c('YearTract','violent','nonviolent','Total_y','vice','X.y','X.x','count_inf',
'hispanic','culture_recreation')
totalFilteredDf = totalDf[,!(names(totalDf) %in% nonNumericCols)]
tractNum = length(unique(totalDf$tract))
XtrainTract = totalFilteredDf[totalDf$Year %in% 2006:2013,]
XtestTract = totalFilteredDf[totalDf$Year %in% 2014:2015,]
Xtrain = XtrainTract[,!(names(XtrainTract) %in% c('tract'))]
Xtest = XtestTract[,!(names(XtestTract) %in% c('tract'))]
genMatirx = as.matrix(Xtrain %>% select(-one_of(c('Y'))))
crossval <-  cv.glmnet(x = genMatirx, y = Xtrain[,'Y'])
lamMin = crossval$lambda.min
lassoTotalModel = glmnet(genMatirx,alpha = 1, Xtrain[,'Y'], lambda = lamMin)
summary(lassoTotalModel)
coeffLasso = coefficients(lassoTotalModel)[,1]
coeffLasso
